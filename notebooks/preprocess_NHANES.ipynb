{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path_to_project = os.path.abspath(os.path.join(os.getcwd(), '../'))    \n",
    "sys.path.insert(1, os.path.join(path_to_project))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from src.data_dict import NHANES_nan_fill\n",
    "from src.directory import data_dir, NHANES_dir, NHANES_preprocessed_filename, NHANES_vars_lookup_filename\n",
    "from src.utils import preprocess_NHANES, download_nhanes_xpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAXMIN_H.xpt already exists. Skipping.\n",
      "SLQ_H.xpt already exists. Skipping.\n",
      "BPX_H.xpt already exists. Skipping.\n",
      "BPQ_H.xpt already exists. Skipping.\n",
      "DIQ_H.xpt already exists. Skipping.\n",
      "BMX_H.xpt already exists. Skipping.\n",
      "SMQ_H.xpt already exists. Skipping.\n",
      "SMQRTU_H.xpt already exists. Skipping.\n",
      "DEMO_H.xpt already exists. Skipping.\n",
      "DPQ_H.xpt already exists. Skipping.\n",
      "RXQ_DRUG.xpt already exists. Skipping.\n",
      "RXQ_RX_H.xpt already exists. Skipping.\n",
      "PAQ_H.xpt already exists. Skipping.\n",
      "PAXDAY_H.xpt already exists. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# read in variable lookup df\n",
    "vars_lookup_df = pd.read_csv(os.path.join(data_dir, NHANES_vars_lookup_filename))\n",
    "\n",
    "# get questionnaire names\n",
    "questionnaires = vars_lookup_df['Data File Name'].apply(lambda x: re.findall('\\(([^)]+)', x)[0]).unique()\n",
    "\n",
    "url_list = [\n",
    "    f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2013/DataFiles/{questionnaire}.xpt\" for questionnaire in questionnaires\n",
    "]\n",
    "\n",
    "# download datasets (if necessary)\n",
    "download_nhanes_xpt(url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NHANES_preprocessed_filepath = os.path.join(data_dir, NHANES_preprocessed_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing PAQ_H.xpt...\n",
      "Preprocessing BPQ_H.xpt...\n",
      "Preprocessing DPQ_H.xpt...\n",
      "Preprocessing PAXDAY_H.xpt...\n",
      "Preprocessing RXQ_RX_H.xpt...\n",
      "Preprocessing SLQ_H.xpt...\n",
      "Preprocessing BPX_H.xpt...\n",
      "Preprocessing SMQRTU_H.xpt...\n",
      "Preprocessing DIQ_H.xpt...\n",
      "Preprocessing BMX_H.xpt...\n",
      "Preprocessing SMQ_H.xpt...\n",
      "Preprocessing DEMO_H.xpt...\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_NHANES(exclude=['RXQ_DRUG.xpt', 'PAXMIN_H.xpt'])\n",
    "df.to_csv(NHANES_preprocessed_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing PAXMIN_H.xpt...\n",
      "Processing chunk 1000000.0 - 2000000.0\n",
      "Processing chunk 2000000.0 - 3000000.0\n",
      "Processing chunk 3000000.0 - 4000000.0\n",
      "Processing chunk 4000000.0 - 5000000.0\n",
      "Processing chunk 5000000.0 - 6000000.0\n",
      "Processing chunk 6000000.0 - 7000000.0\n",
      "Processing chunk 7000000.0 - 8000000.0\n",
      "Processing chunk 8000000.0 - 9000000.0\n",
      "Processing chunk 9000000.0 - 10000000.0\n",
      "Processing chunk 10000000.0 - 11000000.0\n",
      "Processing chunk 11000000.0 - 12000000.0\n",
      "Processing chunk 12000000.0 - 13000000.0\n",
      "Processing chunk 13000000.0 - 14000000.0\n",
      "Processing chunk 14000000.0 - 15000000.0\n",
      "Processing chunk 15000000.0 - 16000000.0\n",
      "Processing chunk 16000000.0 - 17000000.0\n",
      "Processing chunk 17000000.0 - 18000000.0\n",
      "Processing chunk 18000000.0 - 19000000.0\n",
      "Processing chunk 19000000.0 - 20000000.0\n",
      "Processing chunk 20000000.0 - 21000000.0\n",
      "Processing chunk 21000000.0 - 22000000.0\n",
      "Processing chunk 22000000.0 - 23000000.0\n",
      "Processing chunk 23000000.0 - 24000000.0\n",
      "Processing chunk 24000000.0 - 25000000.0\n",
      "Processing chunk 25000000.0 - 26000000.0\n",
      "Processing chunk 26000000.0 - 27000000.0\n",
      "Processing chunk 27000000.0 - 28000000.0\n",
      "Processing chunk 28000000.0 - 29000000.0\n",
      "Processing chunk 29000000.0 - 30000000.0\n",
      "Processing chunk 30000000.0 - 31000000.0\n",
      "Processing chunk 31000000.0 - 32000000.0\n",
      "Processing chunk 32000000.0 - 33000000.0\n",
      "Processing chunk 33000000.0 - 34000000.0\n",
      "Processing chunk 34000000.0 - 35000000.0\n",
      "Processing chunk 35000000.0 - 36000000.0\n",
      "Processing chunk 36000000.0 - 37000000.0\n",
      "Processing chunk 37000000.0 - 38000000.0\n",
      "Processing chunk 38000000.0 - 39000000.0\n",
      "Processing chunk 39000000.0 - 40000000.0\n",
      "Processing chunk 40000000.0 - 41000000.0\n",
      "Processing chunk 41000000.0 - 42000000.0\n",
      "Processing chunk 42000000.0 - 43000000.0\n",
      "Processing chunk 43000000.0 - 44000000.0\n",
      "Processing chunk 44000000.0 - 45000000.0\n",
      "Processing chunk 45000000.0 - 46000000.0\n",
      "Processing chunk 46000000.0 - 47000000.0\n",
      "Processing chunk 47000000.0 - 48000000.0\n",
      "Processing chunk 48000000.0 - 49000000.0\n",
      "Processing chunk 49000000.0 - 50000000.0\n",
      "Processing chunk 50000000.0 - 51000000.0\n",
      "Processing chunk 51000000.0 - 52000000.0\n",
      "Processing chunk 52000000.0 - 53000000.0\n",
      "Processing chunk 53000000.0 - 54000000.0\n",
      "Processing chunk 54000000.0 - 55000000.0\n",
      "Processing chunk 55000000.0 - 56000000.0\n",
      "Processing chunk 56000000.0 - 57000000.0\n",
      "Processing chunk 57000000.0 - 58000000.0\n",
      "Processing chunk 58000000.0 - 59000000.0\n",
      "Processing chunk 59000000.0 - 60000000.0\n",
      "Processing chunk 60000000.0 - 61000000.0\n",
      "Processing chunk 61000000.0 - 62000000.0\n",
      "Processing chunk 62000000.0 - 63000000.0\n",
      "Processing chunk 63000000.0 - 64000000.0\n",
      "Processing chunk 64000000.0 - 65000000.0\n",
      "Processing chunk 65000000.0 - 66000000.0\n",
      "Processing chunk 66000000.0 - 67000000.0\n",
      "Processing chunk 67000000.0 - 68000000.0\n",
      "Processing chunk 68000000.0 - 69000000.0\n",
      "Processing chunk 69000000.0 - 70000000.0\n",
      "Processing chunk 70000000.0 - 71000000.0\n",
      "Processing chunk 71000000.0 - 72000000.0\n",
      "Processing chunk 72000000.0 - 73000000.0\n",
      "Processing chunk 73000000.0 - 74000000.0\n",
      "Processing chunk 74000000.0 - 75000000.0\n",
      "Processing chunk 75000000.0 - 76000000.0\n",
      "Processing chunk 76000000.0 - 77000000.0\n",
      "Processing chunk 77000000.0 - 78000000.0\n",
      "Processing chunk 78000000.0 - 79000000.0\n",
      "Processing chunk 79000000.0 - 80000000.0\n",
      "Processing chunk 80000000.0 - 81000000.0\n",
      "Processing chunk 81000000.0 - 82000000.0\n",
      "Processing chunk 82000000.0 - 83000000.0\n",
      "Processing chunk 83000000.0 - 84000000.0\n",
      "Processing chunk 84000000.0 - 85000000.0\n",
      "Processing chunk 85000000.0 - 86000000.0\n",
      "Processing chunk 86000000.0 - 87000000.0\n",
      "Processing chunk 87000000.0 - 88000000.0\n",
      "Processing chunk 88000000.0 - 89000000.0\n"
     ]
    }
   ],
   "source": [
    "# read in lux values\n",
    "lux_filepath = os.path.join(data_dir, 'lux_df.csv')\n",
    "if os.path.exists(lux_filepath):\n",
    "    lux_df = pd.read_csv(lux_filepath, index_col='SEQN')\n",
    "else:\n",
    "    lux_df = preprocess_NHANES(exclude=[\n",
    "        os.path.basename(x) for x in os.listdir(NHANES_dir) if 'PAXMIN_H.xpt' not in x])\n",
    "    lux_df.to_csv(lux_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sleep_minutes</th>\n",
       "      <th>summed_lux</th>\n",
       "      <th>ambient_light</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEQN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73664.0</th>\n",
       "      <td>6635</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73665.0</th>\n",
       "      <td>11529</td>\n",
       "      <td>6699.11</td>\n",
       "      <td>0.581066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73666.0</th>\n",
       "      <td>11529</td>\n",
       "      <td>39518.93</td>\n",
       "      <td>3.427785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73667.0</th>\n",
       "      <td>11529</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73668.0</th>\n",
       "      <td>11529</td>\n",
       "      <td>519.69</td>\n",
       "      <td>0.045077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83725.0</th>\n",
       "      <td>11529</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83727.0</th>\n",
       "      <td>11529</td>\n",
       "      <td>407178.24</td>\n",
       "      <td>35.317741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83729.0</th>\n",
       "      <td>11529</td>\n",
       "      <td>9644.65</td>\n",
       "      <td>0.836556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83730.0</th>\n",
       "      <td>11529</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83731.0</th>\n",
       "      <td>11529</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7688 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         total_sleep_minutes  summed_lux  ambient_light\n",
       "SEQN                                                   \n",
       "73664.0                 6635        0.00       0.000000\n",
       "73665.0                11529     6699.11       0.581066\n",
       "73666.0                11529    39518.93       3.427785\n",
       "73667.0                11529        0.00       0.000000\n",
       "73668.0                11529      519.69       0.045077\n",
       "...                      ...         ...            ...\n",
       "83725.0                11529        0.00       0.000000\n",
       "83727.0                11529   407178.24      35.317741\n",
       "83729.0                11529     9644.65       0.836556\n",
       "83730.0                11529        0.00       0.000000\n",
       "83731.0                11529        0.00       0.000000\n",
       "\n",
       "[7688 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lux_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with df\n",
    "df = pd.concat([df, lux_df[['ambient_light']]], axis=1)\n",
    "df.to_csv(NHANES_preprocessed_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get descriptive statistics (over missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subjects with valid HTN & sleep deprivation values: 6187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "physical_activity              1.000000\n",
       "sleep_deprivation              1.000000\n",
       "HTN                            1.000000\n",
       "age                            1.000000\n",
       "gender                         1.000000\n",
       "race_ethnicity                 1.000000\n",
       "diabetes                       1.000000\n",
       "GLUCOCORTICOIDS                1.000000\n",
       "ANTIDEPRESSANTS_ANXIOLYTICS    1.000000\n",
       "sleep_troubles                 0.999838\n",
       "daily_sedentary                0.996121\n",
       "BMI                            0.978503\n",
       "smoker                         0.951511\n",
       "poverty_ratio                  0.922903\n",
       "accelerometer                  0.864716\n",
       "depression                     0.856473\n",
       "ambient_light                  0.855019\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indices for rows with valid HTN or sleep deprivation values\n",
    "# valid_HTN_or_deprivation = ~(df['HTN'].isna() & df['sleep_deprivation'].isna())\n",
    "\n",
    "# get indices for rows with valid HTN and sleep deprivation values\n",
    "valid_HTN_and_deprivation = ~(df['HTN'].isna() | df['sleep_deprivation'].isna())\n",
    "\n",
    "total_valid_subjects = valid_HTN_and_deprivation.sum().item()\n",
    "print('Total subjects with valid HTN & sleep deprivation values:', total_valid_subjects)\n",
    "\n",
    "# get ratio of valid responses for each column\n",
    "ratio_of_valid_responses = df[valid_HTN_and_deprivation].describe().loc['count'] / total_valid_subjects\n",
    "ratio_of_valid_responses.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subjects with complete data: 4319\n"
     ]
    }
   ],
   "source": [
    "# get subjects with complete data\n",
    "subjects_with_complete_data = df.dropna(how='any')\n",
    "\n",
    "print('Total subjects with complete data:', len(subjects_with_complete_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute missing data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path_to_project = os.path.abspath(os.path.join(os.getcwd(), '../'))    \n",
    "sys.path.insert(1, os.path.join(path_to_project))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.directory import data_dir, NHANES_preprocessed_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NHANES_preprocessed_filepath = os.path.join(data_dir, NHANES_preprocessed_filename)\n",
    "df = pd.read_csv(NHANES_preprocessed_filepath, index_col='SEQN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['physical_activity', 'depression', 'ANTIDEPRESSANTS_ANXIOLYTICS', 'GLUCOCORTICOIDS', 'sleep_troubles',\n",
    "       'sleep_deprivation', 'diabetes', 'smoker', 'race_ethnicity', 'gender', 'HTN']\n",
    "numerical_cols = ['daily_sedentary', 'accelerometer', 'BMI', 'age', 'poverty_ratio', 'ambient_light']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute numerical values\n",
    "for col in numerical_cols:\n",
    "    fill_value = df[col].mean().item() # mean \n",
    "    df[col] = df[col].fillna(fill_value)\n",
    "\n",
    "# TODO: (optional) MICE imputation / categorical imputation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cph200b_project3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
